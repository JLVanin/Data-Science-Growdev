{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### AVALIAÇÃO FINAL   \n",
        "### MÓDULO EXPLORAÇÃO DE DADOS NA INTERNET"
      ],
      "metadata": {
        "id": "RDJrWE4JuuGL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Objetivo\n",
        "####Raspar os dados de uma livraria online: http://books.toscrape.com/\n",
        "#### Extrair apenas duas informações de cada livro: \n",
        " 1. Título \n",
        " 2. Descrição."
      ],
      "metadata": {
        "id": "u6mmuqhtvjI0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Bibliotecas"
      ],
      "metadata": {
        "id": "108FAGbaQOeS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import re\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "vlgrnu4vqjqk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Função para solicitar e analisar a página Web"
      ],
      "metadata": {
        "id": "OUBDooFeQV2c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-lmzNDJpO6W"
      },
      "outputs": [],
      "source": [
        "url = \"http://books.toscrape.com/index.html\"\n",
        "\n",
        "def getAndParseURL(url):\n",
        "    result = requests.get(url)\n",
        "    soup = BeautifulSoup(result.text, 'html.parser')\n",
        "    return(soup)\n",
        "\n",
        "print(getAndParseURL(url).prettify()[:1000])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Função para buscar links de livros em qualquer página do site"
      ],
      "metadata": {
        "id": "5fPkYf7Z1HVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def getBooksURLs(url):\n",
        "    soup = getAndParseURL(url)\n",
        "    \n",
        "    return([\"/\".join(url.split(\"/\")[:-1]) + \"/\" + x.div.a.get('href')\n",
        "       for x in soup.findAll(\"article\", class_ = \"product_pod\")])"
      ],
      "metadata": {
        "id": "GriXSbYJqWVD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Obter todas as páginas URLs"
      ],
      "metadata": {
        "id": "29vwADTk2k1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pages_urls = [url]\n",
        "\n",
        "soup = getAndParseURL(pages_urls[0])\n",
        "\n",
        "while len(soup.findAll(\"a\", href=re.compile(\"page\"))) == 2 or len(pages_urls) == 1:\n",
        "    new_url = \"/\".join(pages_urls[-1].split(\"/\")[:-1]) + \"/\" + soup.findAll(\"a\", href=re.compile(\"page\"))[-1].get(\"href\")\n",
        "    pages_urls.append(new_url)\n",
        "    soup = getAndParseURL(new_url)\n",
        "    \n",
        "print(str(len(pages_urls)) + \" fetched URLs\")\n",
        "print(\"Some examples:\")\n",
        "pages_urls[:5]"
      ],
      "metadata": {
        "id": "DgvxeE-251jh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Busca todos os URLs dos produtos para cada página"
      ],
      "metadata": {
        "id": "_wPR95xY3Aa5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "booksURLs = []\n",
        "\n",
        "for page in pages_urls:\n",
        "    booksURLs.extend(getBooksURLs(page))\n",
        "    \n",
        "print(str(len(booksURLs)) + \" fetched URLs\")\n",
        "print(\"Some examples:\")\n",
        "booksURLs[:5]"
      ],
      "metadata": {
        "id": "K7p65iACsbMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Busca os dados de cada produto"
      ],
      "metadata": {
        "id": "pA90JpUd3OGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "title = []\n",
        "description = []\n",
        "\n",
        "for url in booksURLs:\n",
        "    soup = getAndParseURL(url)\n",
        "    # product title\n",
        "    title.append(soup.find(\"div\", class_ = re.compile(\"product_main\")).h1.text)\n",
        "    # product description\n",
        "    description.append(soup.find_all('p')[3].get_text())"
      ],
      "metadata": {
        "id": "B5_3UpV_srs7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Armazena dentro de um DataFrame do Pandas."
      ],
      "metadata": {
        "id": "Wa4M-C60-niV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_scraped = pd.DataFrame({'Title': title, 'Description': description})\n",
        "\n",
        "df_scraped"
      ],
      "metadata": {
        "id": "vLyEQ0WAsuzu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}